{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "from langchain.schema import Document\n",
    "from typing import List\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasTranformer:\n",
    "    def __init__(self, df) -> None:\n",
    "        self.df=df\n",
    "        \n",
    "    def load(self)->List[Document]:\n",
    "        # Iterar sobre las filas del DataFrame y crear documentos con metadatos\n",
    "        documents = []\n",
    "        for index, row in self.df.iterrows():\n",
    "            document = {\n",
    "                'content': row['UEN',:],  # Contenido del documento\n",
    "                'metadata': {\n",
    "                    'fecha': row['Fecha'],     # Metadato de fecha\n",
    "                    # Agrega más metadatos aquí si es necesario\n",
    "                }\n",
    "            }\n",
    "            documents.append(document)\n",
    "\n",
    "        # Ahora la lista 'documents' contiene documentos con sus metadatos\n",
    "        print(documents)\n",
    "        return documents\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CARGA DE PRESUPUESTOS\n",
    "sheet_id='1ofJ38O2-dLfw7TZOxeTDYUzlWgl6hN2iMLZCMscTgGo'\n",
    "hoja='Presupuesto'\n",
    "gsheet_url_presupuesto = \"https://docs.google.com/spreadsheets/d/{}/gviz/tq?tqx=out:csv&sheet={}\".format(sheet_id, hoja)\n",
    "df_presupuesto=pd.read_csv(gsheet_url_presupuesto)\n",
    "df_presupuesto = df_presupuesto.convert_dtypes()\n",
    "df_presupuesto['FECHASQL'] = pd.to_datetime(df_presupuesto['FECHASQL'], format='%d/%m/%Y')\n",
    "df_presupuesto=df_presupuesto.dropna(axis=1)\n",
    "\n",
    "\n",
    "#Quiero hacer un dataframe nuevo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls = [gsheet_url_presupuesto]\n",
    "\n",
    "ml_papers = []\n",
    "\n",
    "df_presupuesto[\"FECHASQL\"] = pd.to_datetime(df_presupuesto[\"FECHASQL\"])\n",
    "df_presupuesto[\"FECHASQL\"] = df_presupuesto[\"FECHASQL\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "loader = CSVLoader('C:/Users/gmartinez/Desktop/new/ProyectoChatBot/archivos/presupuesto_data.csv')\n",
    "data = loader.load()\n",
    "ml_papers.append(data)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=200,\n",
    "        length_function=len,\n",
    "        chunk_overlap=50\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=': 200\\nFECHASQL: 2023-05-15\\nUEN: MERC GUAYMALLEN\\nDia: lunes\\nPorcentaje: 3.54%\\nCODPRODUCTO: GNC\\nVENTAS: 3575.4' metadata={'source': 'C:/Users/gmartinez/Desktop/new/ProyectoChatBot/archivos/presupuesto_data.csv', 'row': 200}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(documents[200])\n",
    "type(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[0;32m      7\u001b[0m         document \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m documents \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_documents_to_strings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 7\u001b[0m, in \u001b[0;36mconvert_documents_to_strings\u001b[1;34m(documents)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_documents_to_strings\u001b[39m(documents):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents:\n\u001b[1;32m----> 7\u001b[0m         document \u001b[38;5;241m=\u001b[39m \u001b[43mdocument\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "embedding_st= SentenceTransformerEmbeddings(\n",
    "    model_name = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "\n",
    "def convert_documents_to_strings(documents):\n",
    "    for document in documents:\n",
    "        document = document.text.replace(\"\\n\", \" \")\n",
    "\n",
    "documents = convert_documents_to_strings(documents)\n",
    "\n",
    "\n",
    "#inscrustaciones= embedding_st.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.24.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.12.1)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 715.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.2.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.10.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-win_amd64.whl (977 kB)\n",
      "     -------------------------------------- 977.5/977.5 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence_transformers) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (22.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.6)\n",
      "Requirement already satisfied: joblib in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-2.0.1-cp310-cp310-win_amd64.whl (172.3 MB)\n",
      "     -------------------------------------- 172.3/172.3 MB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (2.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gmartinez\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.2.1)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py): started\n",
      "  Building wheel for sentence_transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125960 sha256=b5a92d9b1e03473719e5ee3d71fb2bdf270fec3c9754c888d0e3a626c9e610a7\n",
      "  Stored in directory: c:\\users\\gmartinez\\appdata\\local\\pip\\cache\\wheels\\0a\\f5\\dd\\9d00836c4e9e279c2a59d5b0ab72dafa66cbc626a327c550dd\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: sentencepiece, torch, torchvision, sentence_transformers\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99 torch-2.0.1 torchvision-0.15.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=': 0\\nFECHASQL: 2023-05-01\\nUEN: ADOLFO CALLE\\nDia: lunes\\nPorcentaje: 3.54%\\nCODPRODUCTO: GNC\\nVENTAS: 2053.2' metadata={'source': 'C:/Users/gmartinez/Desktop/new/ProyectoChatBot/archivos/presupuesto_data.csv', 'row': 0}\n"
     ]
    }
   ],
   "source": [
    "len(documents)\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">CARGANDO CHROMA EXISTENTE\n",
       "</pre>\n"
      ],
      "text/plain": [
       "CARGANDO CHROMA EXISTENTE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "recreate_chroma_db = False\n",
    "def get_chroma_db(embeddings, documents, path):\n",
    "\n",
    "    if recreate_chroma_db:\n",
    "        return Chroma.from_documents(\n",
    "            documents=documents, embedding=embeddings, persist_directory=path\n",
    "        )\n",
    "    else:\n",
    "        console.print(\"CARGANDO CHROMA EXISTENTE\")\n",
    "        return Chroma(persist_directory=path, embedding_function=embeddings)\n",
    "    \n",
    "    \n",
    "vectorstore_chroma = get_chroma_db(embedding_st, data, \"chroma\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Chroma' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(vectorstore_chroma[\u001b[39m0\u001b[39;49m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Chroma' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(vectorstore_chroma[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_chroma.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_chroma = Chroma(\n",
    "    persist_directory= \"chroma\",\n",
    "    embedding_function= embedding_st\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectorstore_chroma.similarity_search_with_score(\"Presupuestos del ultimo mes\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mlen\u001b[39m(docs)\n\u001b[1;32m----> 2\u001b[0m docs[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "len(docs)\n",
    "docs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
